{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3nl50l3lkvbihsh11skv3",
    "id": "Dheykc-SdqsK"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "9r5cibancpvjx1jjy6kl",
    "id": "sB7ElaTEdtHt",
    "outputId": "b0d196c0-4a77-44d8-ded4-decf3a3d2d62"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "%pip install transformers\n",
    "%pip install pyyaml==5.4.1\n",
    "%pip install gdown\n",
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "q85y8wh0otf27py112dgu1",
    "id": "iVYS3gXnDiiE"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cellId": "s349gporhr8o79p8it9zf",
    "id": "LzcgBFlu7_MD",
    "outputId": "7ed2356d-e872-4b09-f11e-484388e909c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cellId": "zu7efb3zgjyrikocsn5c",
    "id": "TqqKTiuwxw1e"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "BERT_TYPE = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cellId": "fzb79smp0ulzfffr3ohj78",
    "id": "HTx3wjD4SmON"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cellId": "wcgqrqrh7og0lor8cj89e6",
    "id": "RSxGejvYy9Yo"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "PAD = 0\n",
    "UNK = 1\n",
    "BOS = 2\n",
    "EOS = 3\n",
    "\n",
    "tgt_vocab_size = 54 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cellId": "xxp5lwfahjrcdc27xxo7pi",
    "id": "Bu8UjSoVo-R_"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "qskxq02j5g8889xxr61hxc",
    "id": "ftOb2zw3o8tx"
   },
   "source": [
    "# Download AAPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cellId": "xdfbyhyl8dj6wv5z3gj65t",
    "id": "6u3S-OIEdhX9",
    "outputId": "c5c81100-c83e-4d10-c845-aa244121b7d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/work/resources/label_test',\n",
       " '/home/jupyter/work/resources/label_train',\n",
       " '/home/jupyter/work/resources/label_val',\n",
       " '/home/jupyter/work/resources/test.tsv',\n",
       " '/home/jupyter/work/resources/text_test',\n",
       " '/home/jupyter/work/resources/text_train',\n",
       " '/home/jupyter/work/resources/text_val',\n",
       " '/home/jupyter/work/resources/train.tsv',\n",
       " '/home/jupyter/work/resources/validation.tsv']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "import gdown\n",
    "\n",
    "url = 'https://drive.google.com/drive/folders/1qw05BnA1O-XDgJ50OgNGFSlTa9Kls00j?usp=sharing'\n",
    "gdown.download_folder(url, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellId": "9jjkf78mp1s2k14rnof1ps",
    "execution": {
     "iopub.execute_input": "2022-05-08T22:20:40.692448Z",
     "iopub.status.busy": "2022-05-08T22:20:40.692211Z",
     "iopub.status.idle": "2022-05-08T22:20:40.696816Z",
     "shell.execute_reply": "2022-05-08T22:20:40.695738Z",
     "shell.execute_reply.started": "2022-05-08T22:20:40.692413Z"
    },
    "id": "ls_txy4OrK6U"
   },
   "outputs": [],
   "source": [
    "# !cp -r drive/MyDrive/AAPD ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cellId": "kq4nuuotrzlgkwokv7rcrr",
    "id": "tsqss4vgkL08"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "!mkdir AAPD\n",
    "!mv *.tsv AAPD\n",
    "!mv text_* AAPD\n",
    "!mv label_* AAPD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "g7nla6nuzcok8haqhg7me",
    "id": "rI6qF9jADOI-"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cellId": "yk24u9gzw19te4iulvhq7",
    "id": "rGJnw0adHdzI"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def apply_to_dict_values(dict, f):\n",
    "    for key, value in dict.items():\n",
    "        dict[key] = f(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cellId": "11frj4o4ohmet5qhjzsyde",
    "id": "1ZvjszV0S5KG"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "\n",
    "class AAPDDataset(Dataset):\n",
    "    \"\"\"AAPD dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.data = pd.read_csv(self.path, sep='\\t', header=None)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(BERT_TYPE)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def target_to_tensor(target):\n",
    "        return torch.tensor([float(label) for label in target])\n",
    "\n",
    "    @staticmethod\n",
    "    def target_to_tensor_with_specials(target):\n",
    "        return torch.tensor([BOS] + [float(index) + 4 for index, label in enumerate(target) if label == '1'] + [EOS])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.tokenizer(self.data.iloc[idx, 1], return_tensors=\"pt\", max_length=512, padding=\"max_length\", truncation=True) # max_len=512 !DocBERT\n",
    "        apply_to_dict_values(data, lambda x: x.flatten())\n",
    "        return data, AAPDDataset.target_to_tensor_with_specials(self.data.iloc[idx, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "k5qga7dhtq8impxafbedg",
    "id": "stCFG3BpsjVY"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "train_dataset = AAPDDataset('./AAPD/train.tsv')\n",
    "val_dataset = AAPDDataset('./AAPD/validation.tsv')\n",
    "test_dataset = AAPDDataset('./AAPD/test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cellId": "eujc5kom8acuqt8itc7lnf",
    "id": "sXRJMMUf0YRj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def padding(data):\n",
    "    src, tgt = zip(*data)\n",
    "\n",
    "    keys = src[0].keys()\n",
    "    src_agg = {}\n",
    "    for key in keys:\n",
    "        agg = [s[key] for s in src]\n",
    "        src_agg[key] = torch.stack(agg)    \n",
    "\n",
    "    tgt_len = [len(t) for t in tgt]\n",
    "    tgt_pad = torch.zeros(len(tgt), max(tgt_len)).long()\n",
    "    for i, s in enumerate(tgt):\n",
    "        tgt_pad[i, :tgt_len[i]] = s.detach().clone()[:tgt_len[i]]\n",
    "\n",
    "    return src_agg, tgt_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cellId": "h05vcrs0ee9fqdfbcba2w",
    "id": "U-good4bDmy2"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=padding)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=padding)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "5uyi0ou74dwvm326q126y",
    "id": "PEdFRi6TeFnY"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "fdc1wzk7l37lk7ejfr6zjp",
    "id": "5QGasR8jCs1E"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cellId": "hqlcnz1i7hh7b3d8rfxzo",
    "id": "VFcwlkmSCoMx"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertConfig\n",
    "\n",
    "\n",
    "class BertEncdoer(nn.Module):\n",
    "    def __init__(self, bert_type=\"bert-base-uncased\", dropout_prob=0.):\n",
    "        super(BertEncdoer, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(bert_type)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        Bert input -> hidden states for SGM attention, (hidden state, cell state) for decoder init \n",
    "        [batch_size, seq_len] -> [batch_size, seq_len, bert_hidden_size], ([1, batch_size, bert_hidden_size] x 2)\n",
    "        1 = n_decoder_layers\n",
    "        '''\n",
    "        bert_output = self.bert_model(**inputs)\n",
    "        pooler_output = self.dropout(bert_output.pooler_output)\n",
    "        return bert_output.last_hidden_state, (None, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "bb9c9tqnqzucrkzgrdz1",
    "id": "-hKgG4uQnKqq"
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cellId": "37rb00cbb4o6hcf9r4q77e",
    "id": "ys3yFeLpuwwv"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class SgmHead(nn.Module):\n",
    "\n",
    "    def __init__(self, tgt_vocab_size, hidden_size):\n",
    "        super(SgmHead, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.inner_hidden_size = 768\n",
    "        self.W_d = nn.Linear(self.hidden_size, self.inner_hidden_size)\n",
    "        self.W_o = nn.Linear(self.inner_hidden_size, tgt_vocab_size)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, hiddens, c_t, prev_predicted_labels=None, use_softmax=False):\n",
    "        scores = self.W_o(self.activation(self.W_d(hiddens)))\n",
    "        I = torch.zeros_like(scores)\n",
    "        if prev_predicted_labels:\n",
    "            for predicted_labels in prev_predicted_labels:\n",
    "                I[(list(range(I.size(0))), predicted_labels)] = -1 * float('inf')\n",
    "        scores = scores + I\n",
    "        if use_softmax:\n",
    "            scores = self.softmax(scores)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4a2o1dnnl0ksm217589zn",
    "id": "PbXhghq3wJzZ"
   },
   "source": [
    "## Transformer decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "cellId": "06uafivqrrnnjrei2aygndr",
    "id": "9Hp5e7uYtwlN"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def generate_square_subsequent_mask(size: int):\n",
    "    \"\"\"Generate a triangular (size, size) mask. From PyTorch docs.\"\"\"\n",
    "    mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "dcvcy3q99h4dfa58ombajf",
    "id": "o8ICv8HxeWy_"
   },
   "source": [
    "# BERT + SGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "cellId": "9p3y10ksaxfsewfrc5nzzc",
    "id": "3p6Rvsx-aFIa"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class BertSGM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertSGM, self).__init__()\n",
    "        tgt_vocab_size = 58\n",
    "        tgt_embedding_size = 768\n",
    "        decoder_hidden_size = 768\n",
    "        decoder_num_layers = 1\n",
    "        dropout_prob=0.2\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, tgt_embedding_size)\n",
    "        self.encoder = BertEncdoer(dropout_prob=dropout_prob)\n",
    "        self.mask = generate_square_subsequent_mask(20).to(device)\n",
    "        self.decoder = nn.TransformerDecoder(nn.TransformerDecoderLayer(d_model=768, nhead=8, batch_first=True), num_layers=decoder_num_layers)\n",
    "        self.sgm_head = SgmHead(tgt_vocab_size=tgt_vocab_size, hidden_size=decoder_hidden_size)\n",
    "        self.criterion = self.create_criterion(tgt_vocab_size)\n",
    "        \n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        context, _ = self.encoder(src)\n",
    "        decoder_input = self.tgt_embedding(tgt[:, :-1])\n",
    "        decoder_output = self.decoder(decoder_input, context, self.mask[:decoder_input.size(1), :decoder_input.size(1)])\n",
    "        pseudo_predicted_labels = []\n",
    "        saved_scores = []\n",
    "\n",
    "        for decoder_output_step, t in zip(decoder_output.split(1, dim=1), tgt[:, 1:].transpose(0, 1)):\n",
    "            scores = self.sgm_head(decoder_output_step.squeeze(1), pseudo_predicted_labels)\n",
    "            saved_scores.append(scores)\n",
    "            pseudo_predicted_labels.append(t)\n",
    "        \n",
    "        scores = torch.stack(saved_scores).transpose(0, 1)\n",
    "        return self.compute_loss(scores, tgt)\n",
    "    \n",
    "    def compute_loss(self, scores, tgt):\n",
    "        loss = 0.\n",
    "        for score, t in zip(scores, tgt[:, 1:]):\n",
    "            loss += self.criterion(score, t)\n",
    "        return loss / tgt.size(0)\n",
    "    \n",
    "    def create_criterion(self, tgt_vocab_size):\n",
    "        weight = torch.ones(tgt_vocab_size)\n",
    "        weight[PAD] = 0\n",
    "        crit = nn.CrossEntropyLoss(weight, ignore_index=PAD)\n",
    "        return crit\n",
    "    \n",
    "    def predict(self, src, max_steps=10):\n",
    "        context, _ = self.encoder(src)\n",
    "        batch_size = src['input_ids'].size(0)\n",
    "        decoder_input = self.tgt_embedding(torch.tensor([BOS for _ in range(batch_size)]).to(device)).unsqueeze(1) # (B, 1, emb_len)\n",
    "        predicted_labels = []\n",
    "        eos_predicted = torch.tensor([False for _ in range(batch_size)]).to(device)\n",
    "        \n",
    "        for _ in range(max_steps):\n",
    "            output = self.decoder(decoder_input, context)\n",
    "            scores = self.sgm_head(output[:, -1], predicted_labels)\n",
    "            prediction = torch.argmax(scores, dim=-1)\n",
    "            y_hat = self.tgt_embedding(prediction.to(device))\n",
    "            \n",
    "            predicted_labels.append(prediction.tolist())\n",
    "            eos_predicted = eos_predicted | (prediction == EOS)\n",
    "            if torch.all(eos_predicted):\n",
    "                break\n",
    "            decoder_input = torch.cat((decoder_input, output[:, -1:]), dim=1)\n",
    "     \n",
    "        return torch.tensor(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "2dzb42o3r5kszmx7t4iao8",
    "id": "3lyKPv3GptgH"
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "cellId": "bvmve3srg8ywksitca57q",
    "id": "4jXyu5SSpwbR"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def one_hot_labels(batch, n_classes=54, n_specials=4):\n",
    "    batch_labels = []\n",
    "    for tensor in batch:\n",
    "        labels = [0 for _ in range(n_classes)]\n",
    "        for elem in tensor:\n",
    "            if elem == EOS:\n",
    "                break\n",
    "            if elem >= n_specials:\n",
    "                labels[elem - n_specials] = 1\n",
    "        batch_labels.append(labels)\n",
    "    return batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "5vgyirgcvdodcif0syz0v",
    "id": "jCWW4Vjesg-8",
    "outputId": "753f375e-2354-44db-810d-751e95725f16"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "!wget https://gist.githubusercontent.com/ArseniyBolotin/7623835da1631b00fb150bcd5b0d909f/raw/wandb_writer.py -O wandb_writer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "cellId": "6cq3vljv4ld9lyf9l8aoa8",
    "id": "1ApIPmpXsP-9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from sklearn import metrics\n",
    "from wandb_writer import WandbWriter\n",
    "\n",
    "def get_metrics(y, y_pre):\n",
    "        hamming_loss = metrics.hamming_loss(y, y_pre)\n",
    "        macro_f1 = metrics.f1_score(y, y_pre, average=\"macro\")\n",
    "        macro_precision = metrics.precision_score(y, y_pre, average=\"macro\")\n",
    "        macro_recall = metrics.recall_score(y, y_pre, average=\"macro\")\n",
    "        micro_f1 = metrics.f1_score(y, y_pre, average=\"micro\")\n",
    "        micro_precision = metrics.precision_score(y, y_pre, average=\"micro\")\n",
    "        micro_recall = metrics.recall_score(y, y_pre, average=\"micro\")\n",
    "        \n",
    "        return {\n",
    "            \"hamming_loss\": hamming_loss,\n",
    "            \"macro_f1\": macro_f1,\n",
    "            \"macro_precision\": macro_precision,\n",
    "            \"macro_recall\": macro_recall,\n",
    "            \"micro_f1\": micro_f1,\n",
    "            \"micro_precision\": micro_precision,\n",
    "            \"micro_recall\": micro_recall\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "vhvnnebs8uhv1udb2tcvl",
    "id": "uKCsZUUdtbXG"
   },
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "cellId": "i17vkvla3fzivgg6zi18r",
    "id": "sdKnwg3TcfvZ"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model = BertSGM().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "cellId": "j8x1nqm793b2yhw4wds8cp",
    "id": "QsMCR79ab-mK"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=2e-5, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "jkjt89xurrpati9n4hnlr",
    "id": "F6EgYtYPt7ny"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "wb_writer = WandbWriter(\"BERT+SGM experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "lpi6trfx5y43qf878qiim",
    "id": "6hgnA0cOegY-"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "cellId": "evdmvmzf206tthtpvrykh",
    "id": "gcflncwvuknu"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "cellId": "u0umye325zloz03jskq9q",
    "id": "Q45wES4Uug-g"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def eval_model(model, dataloader, wb_writer, suffix):\n",
    "    model.eval()\n",
    "\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            apply_to_dict_values(src, lambda x: x.to(device))\n",
    "            tgt = tgt.to(device)\n",
    "            prediction = model.predict(src)\n",
    "            targets.extend(tgt.tolist())\n",
    "            predictions.extend(prediction.t().tolist())\n",
    "\n",
    "    results = get_metrics(one_hot_labels(targets), one_hot_labels(predictions))\n",
    "\n",
    "    if wb_writer:\n",
    "        for k, v in results.items():\n",
    "            name = k\n",
    "            if suffix:\n",
    "                name += suffix\n",
    "            wb_writer.add_scalar(name, v)\n",
    "        wb_writer.next_step()\n",
    "        wb_writer.add_scalar(\"Step\", wb_writer.step)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "cellId": "ws5pausehjdv114s55c2",
    "id": "mk-XVD8VtkuT"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def train_epoch(model, optimizer, dataloader, val_dataloader, val_freq, wb_writer=None):\n",
    "    model.train()\n",
    "    index = 0\n",
    "    for src, tgt in tqdm(dataloader, leave=False):\n",
    "        index += 1\n",
    "        apply_to_dict_values(src, lambda x: x.to(device))\n",
    "        tgt = tgt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(src, tgt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if wb_writer:\n",
    "            wb_writer.add_scalar(\"Batch train loss\", loss.item())\n",
    "            wb_writer.next_step()\n",
    "            wb_writer.add_scalar(\"Step\", wb_writer.step)\n",
    "        if index % val_freq == 0:\n",
    "            eval_model(model, val_dataloader, wb_writer, '_validation')\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "0ooy3nqb5kcmzay456a89a",
    "id": "9hAhxhsc-QSF"
   },
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "koyrh8r7lknpg3lh5vy779",
    "id": "rbhlcAX0xWlC",
    "outputId": "fcbbfec7-e045-4fa8-c9f1-c540e9e29091"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "EPOCHS = 10\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_epoch(model, optimizer, train_dataloader, val_dataloader, 100, wb_writer)\n",
    "    log = eval_model(model, train_dataloader, wb_writer, '_train')\n",
    "    print(log)\n",
    "    log = eval_model(model, val_dataloader, wb_writer, '_validation')\n",
    "    print(log)\n",
    "    torch.save(model, 'decoder_transformer_' + str(epoch) + '.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "36dbbd48-4943-462a-98fb-5abded7c1eaa",
  "notebookPath": "notebookc851b2f93b.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
